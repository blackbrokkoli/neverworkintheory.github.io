hi everyone good afternoon evening or morning depending on where you are right now super excited to be here beyond excited to talk to you guys about some work that i have done and i'm continuing to work on that i think will be of interest uh to all parties here and that is the work that i've been doing on causal testing understanding defects root causes so today specifically i'm going to talk to you all about first how we and by we i mean me how i got here to talk to you about causal testing today i'm going to talk to you about causal testing which at its foundation is just a method for improving what you already do with what already exists i'm going to talk about other areas and ways that causal testing can be used in practice and i'm going to talk a little bit about whether it's actually found to be useful starting with how we got here what's the back story right like how how do we even get to talking about causal testing today well it all started with a study that i uh collaborated on ten years ago this year or next year coming up on 10 years ago which is absolutely outrageous to think about um but in my phd we at the beginning of my phd we were really interested in getting a kind of foundational understanding of uh in the space of all the tools that are available for developers why do they use the ones they do use and why don't they use the ones that they don't use right and so this is a really fun study to run uh and from that we found a few things so we found that some of the major issues that developers have with the tools that are available to them are around the tool output so issues around digesting and understanding the output more specifically understanding the results that the tool provides and answering questions like why why is this a problem why should i care what do i do differently tool design issues which i think we can all agree the list here probably goes on and on but different things cited under there and then also workflow integration tools that are that seem awesome and maybe could be great but require some overhead to integrate into their current processes and so from the study i went on a mission to provide what would be considered useful usable and most importantly validated as being such interventions for improving software practice so now fast forward some years to a post phd i ended up getting an opportunity to do a postdoc and in that postdoc i was given the opportunity to work in the testing space which was actually extremely exciting for me because in my phd i spent a lot of time focused on static analysis and really only got to touch a little bit on the dynamic analysis side of things so i was really excited to have this opportunity and of course we already know that testing is a powerful and commonly used way of assessing and validating and or improving software quality but some of the a couple things that emerged or that i got a deeper understanding of as i did this work or at least started doing this work uh was that there are a lot of testing techniques that are available for you some have come from research some are from practice some are a nice balance of both but there are a lot out there um and i also noticed that traditional testing alone doesn't actually answer the question why is this happening right it'll help us find a defect it'll help us even locate it in our code to some extent um but it doesn't always it almost never answers the question why did this behavior happen and so from doing some of this kind of background work and reading uh came to a question of can we take what developers are already doing and the work that's already being done to provide insights that existing tools don't currently provide specifically in this case helping answer the why question why is this happening and so to this question we provided a possible solution that we i'll talk more in depth about in terms of why it is a solution and that would be causal testing so this is where causal testing comes in right so causal testing uh is a method for conducting automated causal experiments uh and this process starts with your existing test cases and uses existing debugging techniques such as fuzzing and automated test generation uh with a goal of providing developers with minimally different passing and failing executions that help reason about why that failing behavior happened to begin with so how does causal testing do that how does that work let's dig a little deeper and talk about the the process of using causal testing right so say you have a test suite and maybe you have some continuous integration set up or something like that where a test fails and you get notified of it so say you have this notification or bug report that comes up directions from this location to that location are wrong right and so let's say we got that book report because this specific test failed so what causal testing does is it takes this failing test and it takes the inputs from this failing test and it attempts to perturb them in meaningful ways to produce additional valid tests that we can execute and determine and keep track of whether they are passing or they're failing once we have a set of passing and failing tests causal testing compares these tests to the original using both the input to the test as well as the execution path that it takes in order to present the developer with the most similar tests assuming that that means that these are the most relevant to that original failing execution and so in this example given these similar passing and failing tests we pretty quickly are able to determine that our passing tests are starting and ending in the same country whereas our failing tests are starting and ending in different countries and so now we have a better understanding with minimal effort of why this test failed to now go and address it

so you might be thinking i'm hoping you're thinking wow that's like so simple and so cool i know it got me excited too and you might also be thinking what else can we do with this also what i'm thinking so let's talk about it what else can causal testing do is it a one-trick pony or can it be applied other places well a couple of directions that we're looking at are first uh causal fairness testing and so uh and this work we actually have published as a demo and there is a prototype that has been developed at the link provided here but so causal fairness testing takes this causal experimentation approach in the context of detecting bias so let's say for example we have some software and that software takes some inputs for simplicity's sake yeah let's say it's some loan software that takes these four inputs to make a decision what causal fairness testing does is it automatically generates tests that look something like this we have some input based on our input space it goes into the loan software and we observe what is the outcome of that input based on that test causal testing makes small singular changes to the input so for example changing green britney's race to orange brittany right and conducts the same test where we feed it into the software and observe the outcome flip one additional attribute one singular attribute observe the outcome and we do that over and over and over again within some threshold to help answer questions such as how often is the outcome of my software different just because of race right so providing a method for for kind of uh if you're worried about software that may have liability concerns or accountability concerns around bias or fairness providing a method for you to not have to create those tests on your own to be able to automatically generate tests that can help speak to those types of concerns so that's one space where causal fairness testing could be useful or causal testing another space that we're looking at that i think is uh really important to to really dig into is this idea of testing machine learning based software and so the work we're doing right now is looking at so for example say you have some software and that software integrates some trained machine learning model that aids in the decision making right and into that software or some sets of inputs let's say for this software we care about name raise zip code and the degree that they have right and then presumably there is either some concrete set of outputs or classes of outputs since we are using a machine learning model here that we want to make sure our software is is is complying with with respect to our expectations right so what we're starting right now is what does it look like to test this type of software particularly in the mode of testing that we typically use uh that being assertions right so can we write assertions that look something like this where we assert equal uh output or outcomes for two sets of inputs and then another example asserting true that for some input we end up in a class or some specific output and if this is something that we can do then we can actually start to think about causal testing being beneficial in this context as well for us to be able to for example see that if we change april to atom right our assertion doesn't break versus here it is breaking right if we keep doing that and we get enough tests then we can start to reason about why something about this input space is causing unexpected behavior all right just another step in the information chain that's required not only to understand behavior but to actually rectify so two directions super excited about we're working on in our lab right now but you might be of course wondering which you should be wondering is it actually useful can i take this technique and do something meaningful with it in practice and we developed a proof of concept implementation to evaluate exactly this where we found that in terms of improving the ability to detect root cause fixing these defects and being useful causal testing checks all the boxes and more specifically in terms of being useful these similar passing tests point to the cause in terms of our according to our participants and so in summary causal testing is a useful technique that provides more insight into faulty executions with code that you've already written so don't hesitate look into the work talk to me about it let's figure out how causal testing can become a part of your testing process thank you so much for your time