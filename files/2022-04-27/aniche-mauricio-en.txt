Hello everybody my name is Mauricio and I'm here to stand up for code coverage today. Why is that? Well, because I'm pretty sure we all heard stuff like, "Code coverage is useless because it can be tricked, or because it forces me to write useless tests, or because, you know, if you write tests without assertions your coverage will be high but your tests will not be testing anything, or 100 code coverage, it doesn't mean your tests are goods, blah blah blah." But let me tell you something: if you really believe on that, it's just because you are not using it properly, you know, make drop time, and that's it. No worries there's a way to use code coverage and let's talk about it now.
First of all, code coverage should be used to augment - to improve your test suites, and not as something you just have to have, right? What do i mean by augment the test suites? So think of how developers write software. So you get some functionality to implement. You then start some loop of implementing a little bit of production codes then a little bit of test code - it doesn't matter if you do test driven development or not - at some point you're just kind of done, and then a big question arises, and the question is, "Is this testing enough? Did I test everything I had to test?" And this is precisely where code coverage kicks in, because you can get the information from it. And then how do you do this? Well, you run your code coverage tool, you see what you covered, what you didn't cover, you reflect about it, you may write more tests, you repeat the cycle until you feel you're done, and when you're done you're done, right?
Let me talk a little bit more about this, how we how we know we are done, right? Usually the questions I ask myself is, when I look at the line that is not covered, for example, I ask myself, why isn't this covered? Because when I was writing the tests with the specification in mind, why did I miss this line, right? Maybe there's a reason for that. Maybe I just forgot about it, then I just write the test. But maybe it's just because it is something that doesn't really deserve to be tested, maybe it's just a getter method that I don't feel like testing right now because, you know, writing a test for it will not really be a strong test - it will never reveal a bug or something, right, so this is how I answer this, "Is this enough?" And the last bullet point there, you know, this is something you should always avoid, you should not write a test just because, you know, you want to increase your coverage number, that's not a good reason to write a test.
Cool so you know code coverage is used to augment your tests, and what we just saw is also the code coverage should help you taking the decision of writing tests - more tests - or not, but it should not be the one taking the decision for you, right, you are in control. Code coverage is just giving you information. Then the one million dollar question: does higher coverage really lead to better software. So I never researched code coverage myself, but a lot of smart people have done, and I'm going to just walk you through some of the papers that I like.
So for example the first one by hutchins and colleagues from 1994, so a long time ago, they compared different test suites with different coverage, and they saw the effectiveness of these test suites. And the findings are that the test suites that achieve over 90 percent coverage are better at detecting faults than the suites that don't achieve that much coverage. And that makes sense, right, the more you coverage - the more you cover - the more bugs you can find, therefore it's just better.
And another interesting finding that also matches with our perception is that 100 coverage alone is not reliable - it's not enough to indicate if your test suite is good enough. So this means if you have 100 coverage that doesn't mean your tests are perfect or something like that.
Then another piece of research from 2009 - and - interesting findings as well. One of them is, if you just keep adding tests by itself, this is not an efficient strategy. What do you need to do you need to write tests for things you didn't test yet. So you look at the coverage and then you write a test for that, and these tests will be more likely to find new faults than if you just keep adding tests for things you tested already. That makes a lot of sense, right, and that actually matches with the procedure I just gave you before: so you write tests based on the specification when you're implementing your feature. Once you're done you augment your test suites using coverage.
One more piece of research, so in this piece of paper - in this work - the authors found that coverage is not always related to effectiveness, so maybe high coverage doesn't really mean that your tests are good, but the authors conclude that coverage is super good to identify under-tested parts of the system, right, but super bad if you're using this as a quality target. So what what do I get from this is, you should never define a coverage target, you know, if your company has that magical number you should always go for, let's say, 90 coverage or whatever, this is maybe not a very good idea.
Finally, we have all sorts of different coverage criteria - line coverage, branch coverage, condition branch coverage, MCDC, path coverage, etc etc etc, but maybe you don't need all those fancy criteria. Statement coverage seems to be a very good indicator of how good your tests are, right? The simplest one - statement coverage - any tool can calculate that, it doesn't really matter the programming language, so you don't have to really go for super fancy stuff: basic stuff always works, right, and I love that.
A final piece of advice, something we also got from these papers, is that high coverage may not mean much, right, 100 percent coverage doesn't mean your tests are perfect, but low coverage means a lot, right, it means your test suite is weak - it may not reveal all the bugs you want to reveal. Shameless self-promotion, I just wrote a book on software testing, there's an entire chapter about this. Let me sum up my talk, so, don't hate code coverage because code coverage doesn't hate. You - we just have to use it properly. How do we do this? We use coverage to augment our test suite, we use coverage to inform the decision of should I test a little bit more or not, but it doesn't take the decision for you, and finally, high coverage may not mean much, but low coverage does mean a lot. Thank you so much.
