um software rarely works as intended while it's being written things go wrong we know that a standard behavior in some software development is see the bug swat the bug and be done with it

in contrast one of the things that i've observed over time is that for experts error or more broadly things that go wrong or go amiss during software development is opportunity to understand better to question assumptions to detect miscommunication or misconceptions to stumble onto insight so experts are not fearful of error but watchful they often hold off swatting the bug instead asking that's odd why is that so indeed error is seen as a useful input in the course of progressive development so this talk is meant to summarize some of the insights about how experts and high performing teams use that opportunity

i've spent some 30 years studying experts and high performing teams uh at work in industry in order to act to articulate their strategies and practices um and in effect i act as a mirror or a lens reflecting and focusing i'm most interested in articulating what successful software developers actually do not in dictating to them what they should do and i'm hoping that the talk will have some resonance with your experience

um research in software engineering predominantly considers error retrospectively based on analysis of software and operation usually of massive projects usually in the context of flaws left in the code that need to be fixed or of software system failures that arise from a collection of smaller flaws we've been taking a more ecological view of error during software development

the psychology literature offers the concept of active error these human errors during a task that take the form of slips of action things like typos or lapses of memory or attention or mistakes made in forming and executing intentions during problem selling so bad decisions for recovery a person must know that an error has occurred must identify both what was done wrong and what should have been done and then must understand how to undo the effects of the error so active errors can be caught in the act or they may be detected later during standard checks and evaluation by obstacles to progress from cues from the environment or through unexpected outcomes so error detection and recovery unfold in the course of progressive problem solving so what is it that experts and high performing teams do that gives them better results

experts mind the gaps rather than just looking for what they expect they pay attention to the feedback and cues that might alert them to something unexpected something amiss they pay attention to the spaces between things so for example to interfaces interactions between components integration with other systems domain concepts hidden behind standard data types they pay attention to what isn't shown to what's missing whether from the design or from the information or from the reasoning tool that they're using and this minding of the gaps promotes detection of flaws

whereas many people look for evidence that things are working as expected experts in high performing teams are more available to contrary evidence and indeed their practices prime them to look for it they seek evidence they ask why they engage users they de-correlate eliciting and contrasting different perspectives so they challenge themselves they challenge their assumptions their models their designs through mechanisms such as the skeptic in the corner or pair debugging they seek falsification they don't just ask how would i know if this is right but they also ask how would i know if this were wrong and how would i would know if an alternative were right importantly they understand that code is read by people and they write comments about what is not in the code that is their intentions and assumptions

understanding something by breaking it as a form of analytic that's common in many branches of engineering introducing errors or flaws deliberately can be a way of gaining insight into how a system operates experts who have experience doing that intentionally to test their system also see unexpected breakage as a potential analytic and sees the opportunity to use it

in contrast to eliminating bugs as quickly as possible experts reflect on the problem and on the solution model they recognize that a small bug may sink signal something more rather than dismissing simple bugs as novice errors or one of those things they look around to detect if there's a fuller story thereby often detecting other deeper issues such as design flaws or misconceptions

so experts don't just fix the bug the one bug they stand back and look for the other bugs that hang out with it they consider dependencies and reflect on the code structure in order to understand whether the bug is part of a bigger picture

and this is all part of reassessing the landscape and deliberately expanding the search space a way of examining barriers understanding constraints revealing assumptions looking beyond the immediate issues and hence potentially admitting more potential solutions or broadening the definition of the problem in a way that provides insight and overcomes flaws and they do this periodically throughout the design and development process not just at the beginning now this is at odds with many software development methodologies which typically concern convergence to a solution and so sometimes the high performing teams step away from a methodology this business of standing back and reflecting on the landscape is crucial we all know of examples where the software met the spec but the specification was inadequate

software developers don't work in an ideal world we know that but rather in an environment dominated by conflicting demands and time pressures so bugs are understood in the context of software use effective triage has to do with a cost-benefit assessment of the relative impact of the bug against the cost of fixing it bugs that aren't important are often tolerated or deferred brian randall encompasses this in his concept of dependability his definition leaves room for imperfection in the code if the imperfection doesn't impair the software's dependability so tolerance is about managing the bug technically but also about managing the bug socially leaving compilation warnings in the code as reminders documenting the deferral and its rationale

similarly developers have been shown to compromise at times in order to keep the work moving along the strategies may include deliberate sub-optimal choices calculated to serve immediate needs but enabling progressive improvements so deliberate compromising suggests that the developer is actively managing the issue over time implementing incremental pragmatic solutions as required to advance the larger program of work this strategy allows the developer to explore the problem over time and ultimately to find the better solution

but in addition to this developers have safety nets and one of them is pair debugging pair debugging is something most of the high performing teams do and people don't talk about much they sit together and talk through the code often deliberately um matching people of notionally different levels of expertise or who know different parts of the code base and this brings a fresh perspective to the code spreads the knowledge of the code among the team and has a tendency to expose assumptions misconceptions and miscommunications

expert experts reflect on their tools as well as their code how can you verify that an analysis tool is doing what it's meant to well experts play methods against each other to increase the likelihood of detections for example building errors into code to test the test harness experts address tool limitations by combining or swapping among multiple tools to quote one developer often it's a mishmash of different ways of thinking that gets you the answer so multiple techniques and tools imply more ways to think but they also require greater cognitive overheads and that requires intelligent coordination so the selection is not arbitrary teams try tools assess their merits assemble tool kits that both fit their development culture and span different perspectives

so in summary experts use systematic discipline practices that are socially embedded and reinforced

importantly because there is a disciplined culture they're able to rely on the team to catch slips thereby giving individuals the freedom to experiment a study of high performing teams makes it clear that the interplay between developers is crucial um plays a crucial part in both nurturing creativity and innovation and in handling errors effectively and embedding systematic practice and rigor so the team culture which leverages both individual strengths and multiples perspectives provides the safety net

there is a caveat to this approach to error which is that the focus is on fixing the error rather than fixing the blame the team culture matters it embodies the mindset that sees error as opportunity that embraces multiple perspectives that reinforces practices such as triage or playing methods against each other or pair programming that routinely challenge understanding and assumptions this helps strengthen and develop the team as well as improving the software but differently software expertise doesn't happen by accident there are these are practices that you can understand and invest in by making space in your organizational culture and by investing time for this mindset these sorts of practices these dialogues you're making space for expertise to work and to grow and for expert level software development to to become possible so perhaps treat this as an opportunity to reflect on your practice thank you for listening
